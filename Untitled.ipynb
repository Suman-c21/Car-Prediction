{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYihB3gLatGftMCpTXiFuX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suman-c21/Car-Prediction/blob/main/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "go96qO6-LrfC",
        "outputId": "d96570f2-56e8-42d6-d94b-d0cf97da239d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2b19ca2a9fb2>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# this randomness. However this is not necessary for your own applications.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "###############################################################################\n",
        "# 2. BUILD THE MODEL ARCHITECTURE #############################################\n",
        "###############################################################################\n",
        "from tensorflow.keras.layers import  Activation, UpSampling3D\n",
        "from tensorflow.keras.models import Model\n",
        "#import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "#import random\n",
        "from keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv3D, MaxPooling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import  layers, regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "#from keras.layers import Attention\n",
        "\n",
        "# For consistency\n",
        "# Since the neural network starts with random initial weights, the results of this\n",
        "# example will differ slightly every time it is run. The random seed is set to avoid\n",
        "# this randomness. However this is not necessary for your own applications.\n",
        "seed = 42\n",
        "np.random.seed = seed\n",
        "\n",
        "def conv_block(x, size, dropout):\n",
        "    # Convolutional layer.\n",
        "    conv = layers.Conv3D(size, (3, 3, 3), kernel_initializer='he_uniform', padding=\"same\")(x)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    conv = layers.Conv3D(size, (3, 3, 3), kernel_initializer='he_uniform', padding=\"same\")(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "    return conv\n",
        "\n",
        "def gating_signal(input, out_size):\n",
        "    # resize the down layer feature map into the same dimension as the up layer feature map\n",
        "    # using 1x1 conv\n",
        "    # :return: the gating feature map with the same dimension of the up layer feature map\n",
        "    x = layers.Conv3D(out_size, (1, 1, 1), kernel_initializer='he_uniform', padding='same')(input)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def attention_block(x, gating, inter_shape):\n",
        "    shape_x = K.int_shape(x)  # (None, 8, 8, 8, 128)\n",
        "    shape_g = K.int_shape(gating)  # (None, 4, 4, 4, 128)\n",
        "    # Getting the x signal to the same shape as the gating signal\n",
        "    theta_x = layers.Conv3D(inter_shape, (2, 2, 2), strides=(2, 2, 2), kernel_initializer='he_uniform', padding='same')(\n",
        "        x)  # 16\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "    # Getting the gating signal to the same number of filters as the inter_shape\n",
        "    phi_g = layers.Conv3D(inter_shape, (1, 1, 1), kernel_initializer='he_uniform', padding='same')(gating)\n",
        "    upsample_g = layers.Conv3DTranspose(inter_shape, (3, 3, 3),\n",
        "                                        strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2],\n",
        "                                                 shape_theta_x[3] // shape_g[3]),\n",
        "                                        kernel_initializer='he_uniform', padding='same')(phi_g)  # 16\n",
        "    concat_xg = layers.add([upsample_g, theta_x])\n",
        "    act_xg = layers.Activation('relu')(concat_xg)\n",
        "    psi = layers.Conv3D(1, (1, 1, 1), kernel_initializer='he_uniform', padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = layers.UpSampling3D(\n",
        "        size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2], shape_x[3] // shape_sigmoid[3]))(\n",
        "        sigmoid_xg)  # 32\n",
        "#     upsample_psi = repeat_elem(upsample_psi, shape_x[4])\n",
        "    y = layers.multiply([upsample_psi, x])\n",
        "    result = layers.Conv3D(shape_x[4], (1, 1, 1), kernel_initializer='he_uniform', padding='same')(y)\n",
        "    return result\n",
        "\n",
        "# Parameters for model\n",
        "img_height = x_train.shape[1]  # 64\n",
        "img_width = x_train.shape[2]  # 64\n",
        "img_depth = x_train.shape[3]  # 64\n",
        "img_channels = x_train.shape[4]  # 12\n",
        "input_shape = (img_height, img_width, img_depth, img_channels)\n",
        "\n",
        "def Attention_UNet_3D_Model(input_shape):\n",
        "    # network structure\n",
        "    filter_numb = 64 # number of filters for the first layer\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, convolution + pooling\n",
        "    conv_64 = conv_block(inputs, filter_numb, dropout=0.10)\n",
        "    pool_32 = layers.MaxPooling3D((2, 2, 2), padding=\"same\")(conv_64)\n",
        "    # DownRes 2\n",
        "    conv_32 = conv_block(pool_32, 2 * filter_numb, dropout=0.15)\n",
        "    pool_16 = layers.MaxPooling3D((2, 2, 2), padding=\"same\")(conv_32)\n",
        "    # DownRes 3\n",
        "    conv_16 = conv_block(pool_16, 4 * filter_numb, dropout=0.20)\n",
        "    pool_8 = layers.MaxPooling3D((2, 2, 2), padding=\"same\")(conv_16)\n",
        "    # DownRes 4\n",
        "    conv_8 = conv_block(pool_8, 8 * filter_numb, dropout=0.25)\n",
        "    pool_4 = layers.MaxPooling3D((2, 2, 2), padding=\"same\")(conv_8)\n",
        "    # DownRes 5, convolution only\n",
        "\n",
        "    conv_4 = conv_block(pool_4, 16 * filter_numb, dropout=0.30)\n",
        "\n",
        "    # Upsampling layers\n",
        "    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n",
        "    gating_8 = gating_signal(conv_4, 8 * filter_numb)\n",
        "    att_8 = attention_block(conv_8, gating_8, 8 * filter_numb)\n",
        "    up_8 = layers.UpSampling3D((2, 2, 2), data_format=\"channels_last\")(conv_4)\n",
        "    up_8 = layers.concatenate([up_8, att_8])\n",
        "    up_conv_8 = conv_block(up_8, 8 * filter_numb, dropout=0.25)\n",
        "    # UpRes 7\n",
        "    gating_16 = gating_signal(up_conv_8, 4 * filter_numb)\n",
        "    att_16 = attention_block(conv_16, gating_16, 4 * filter_numb)\n",
        "    up_16 = layers.UpSampling3D((2, 2, 2), data_format=\"channels_last\")(up_conv_8)\n",
        "    up_16 = layers.concatenate([up_16, att_16])\n",
        "    up_conv_16 = conv_block(up_16, 4 * filter_numb, dropout=0.20)\n",
        "    # UpRes 8\n",
        "    gating_32 = gating_signal(up_conv_16, 2 * filter_numb)\n",
        "    att_32 = attention_block(conv_32, gating_32, 2 * filter_numb)\n",
        "    up_32 = layers.UpSampling3D((2, 2, 2), data_format=\"channels_last\")(up_conv_16)\n",
        "    up_32 = layers.concatenate([up_32, att_32])\n",
        "    up_conv_32 = conv_block(up_32, 2 * filter_numb, dropout=0.15)\n",
        "    # UpRes 9\n",
        "    gating_64 = gating_signal(up_conv_32, filter_numb)\n",
        "    att_64 = attention_block(conv_64, gating_64, filter_numb)\n",
        "    up_64 = layers.UpSampling3D(size=(2, 2, 2), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, att_64])\n",
        "    up_conv_64 = conv_block(up_64, filter_numb, dropout=0.10)\n",
        "\n",
        "    # final convolutional layer\n",
        "    conv_final = layers.Conv3D(1, (1, 1, 1))(up_conv_64)\n",
        "    conv_final = layers.Activation('linear')(conv_final)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[conv_final], name=\"Attention_UNet_3D_Model\")\n",
        "    model.summary()\n",
        "\n",
        "    from keras.optimizers import Adam\n",
        "    learning_rate = 0.001\n",
        "    optimizer = Adam(learning_rate)\n",
        "\n",
        "#     model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics=['accuracy', 'mae'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# Test if everything is working ok.\n",
        "model = Attention_UNet_3D_Model(input_shape)\n",
        "print(model.input_shape)\n",
        "print(model.output_shape)\n",
        "\n"
      ]
    }
  ]
}